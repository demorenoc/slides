{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Moving and Transforming Data with\n",
    "\n",
    "# Airflow\n",
    "\n",
    "<br/>\n",
    "\n",
    "![Airflow](https://raw.githubusercontent.com/apache/incubator-airflow/master/airflow/www/static/pin_100.png)\n",
    "\n",
    "<br/>\n",
    "\n",
    "*[Daniel Moreno](https://github.com/demorenoc)*\n",
    "\n",
    "*Data Science & Analytics - [Mercadoni](https://www.mercadoni.com.co)*\n",
    "\n",
    "*PyCon Colombia (2017-02-11)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Hi\n",
    "<br/>\n",
    "I am Daniel.\n",
    "\n",
    "I am a statistician.\n",
    "\n",
    "\n",
    "<i class=\"fa fa-github\" aria-hidden=\"true\"></i> [@demorenoc](htpps://github.com/demorenoc)\n",
    "<br/>\n",
    "<i class=\"fa fa-linkedin\" aria-hidden=\"true\"></i> [in/demorenoc](https://www.linkedin.com/in/demorenoc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Currently:\n",
    "<img src=\"https://s29.postimg.org/pm48ubxfr/mercadonilogobig_3x.png\" alt=\"Mercadoni\" style=\"width: 300px;\"/>\n",
    "\n",
    "### Previously:\n",
    "<img src=\"https://tappsi.co/wp-content/press-kit/logo/logo-principal-02.png\" alt=\"Tappsi\" style=\"width: 300px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Outline\n",
    "\n",
    "- Motivation\n",
    "\n",
    "- Whishlist\n",
    "\n",
    "- Airflow\n",
    "\n",
    "- Airflow - Components\n",
    "  - API and Concepts\n",
    "  - Scheduler\n",
    "  - Web UI\n",
    "  - CLI\n",
    "\n",
    "- Airflow - Deployment (brief)\n",
    "\n",
    "- Resources and References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Motivation\n",
    "\n",
    "- Modern companies operate on complex and diverse processes powered by technology and producing diverse and vast amounts of data\n",
    "\n",
    "![](http://www.intorobotics.com/wp-content/uploads/2014/10/HRInternetofThingsStandardsiStockphoto27050372-1393867723706.jpg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Motivation\n",
    "\n",
    "- *Continously available* and *usable* data is key for modern companies success.\n",
    "- \"Clean\" data is vital for: \n",
    "  - Better decision making\n",
    "  - Continuous improvement (Measure-Analyze-Improve)\n",
    "  - Reaserch and Development\n",
    "  \n",
    "![](http://databasesquad.net/wp-content/uploads/2014/08/data-warehouse-services.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Motivation\n",
    "\n",
    "- **Moving and transforming data** can get costly, specially when needed continously:\n",
    "  - Overlooked process in early stages\n",
    "  - Large diversity of tools producing complex and specialized \"stacks\"\n",
    "  - Cleaning takes around 80% of the time in data analysis\n",
    "  - Task repetition and redundancy\n",
    "\n",
    "![](http://vignette3.wikia.nocookie.net/lego/images/6/6c/Janitor.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Motivation\n",
    "\n",
    "## How does your company manage their data *workflows*?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "![](img/mercadoni-etl.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Wishlist\n",
    "\n",
    "![](https://decisions.com/wp-content/uploads/2015/11/99-c.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Wishlist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Compact, homogeneous **code**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Simplicity (defining workflows and **colaborating**)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Flexibility (modularity + extensibility)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Traceability/accountability and ownership"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Operational metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Scalability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Automation (**programmatic**/dynamic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Useful UI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Flat learning curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Airflow\n",
    "\n",
    "<br/>\n",
    "\n",
    "![Airflow](https://raw.githubusercontent.com/apache/incubator-airflow/master/airflow/www/static/pin_100.png)\n",
    "\n",
    "![Incubator](http://incubator.apache.org/images/egg-logo2.png)\n",
    "\n",
    "Originally by [Maxime Beauchemin @mistercrunch](https://github.com/mistercrunch) from Airbnb.\n",
    "<br/>\n",
    "\n",
    "https://github.com/apache/incubator-airflow\n",
    "\n",
    "https://airflow.incubator.apache.org/\n",
    "\n",
    "<br/>\n",
    "\n",
    "```sh\n",
    "pip install airflow\n",
    "pip install \"airflow[mysql]\"\n",
    "pip install \"airflow[postgres]\"\n",
    "pip install \"airflow[crypto, password]\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Alternatives\n",
    "\n",
    "- Luigi by Spotify <img src=\"https://raw.githubusercontent.com/spotify/luigi/master/doc/luigi.png\" alt=\"Luigi\" style=\"width: 150px;\"/>\n",
    "\n",
    "- Pinball by Pinterest\n",
    "\n",
    "- See a some comparisons:\n",
    "     - [Luigi vs Airflow vs Pinball](http://bytepawn.com/luigi-airflow-pinball.html#luigi-airflow-pinball)\n",
    "     - [Apache Airflow - Presentation by Sumit Maheshwari (Quoble)](http://www.slideshare.net/sumitmaheshwari007/apache-airflow)\n",
    "\n",
    "## For Hadoop\n",
    "\n",
    "- Azkaban by LinkedIn\n",
    "\n",
    "- Apache Oozie (originally by Yahoo!) ![](http://oozie.apache.org/images/oozie_200x.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Airflow - Components\n",
    "\n",
    "![Airflow-Architecture](https://image.slidesharecdn.com/june101115amairbnbbeaucheminv2-150701231554-lva1-app6892/95/airflow-an-open-source-platform-to-author-and-monitor-data-pipelines-23-638.jpg)\n",
    "\n",
    "Image from [Maxime Beauchemin's original presentation in the 2015 Hadoop Summit](http://www.slideshare.net/Hadoop_Summit/airflow-an-open-source-platform-to-author-and-monitor-data-pipelines) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Airflow - Components\n",
    "\n",
    "- API (http://airflow.incubator.apache.org/code.html#api-reference)\n",
    "```python\n",
    "from airflow import DAG\n",
    "from airflow.operators import SimpleHttpOperator, MySqlOperator\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Executor (\"backend\" system)\n",
    "    - Sequential\n",
    "    - Local\n",
    "    - Celery (and Mesos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Scheduler\n",
    "        airflow scheduler -n 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Web UI\n",
    "        airflow webserver -p 80"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- CLI\n",
    "        airflow --help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Airflow - API and Concepts\n",
    "\n",
    "![](img/dag-example-0.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Airflow - API and Concepts\n",
    "\n",
    "### Workflow Building Blocks - DAG\n",
    "\n",
    "- Building a workflow -- a set of tasks with a dependency structure -- is the main goal.\n",
    "- Workflows are modeled as DAGs: Directed Acyclic Graphs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "```python\n",
    "from airflow import DAG\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "default_args = {'owner': 'daniel', 'email': ['daniel.moreno@mercadoni.com'],\n",
    "                'start_date': datetime(2017, 2, 10), 'depends_on_past': False,\n",
    "                'retries': 1, 'retry_delay': timedelta(seconds = 30)}\n",
    "\n",
    "dag = DAG(dag_id            = 'model',\n",
    "          schedule_interval = timedelta(minutes = 10), # '0/10 * * * *'\n",
    "          default_args      = default_args,\n",
    "          dagrun_timeout    = timedelta(minutes = 3)\n",
    "          template_searchpath = ['path/to/queries'])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Airflow - API and Concepts\n",
    "\n",
    "### Workflow Building Blocks - Operators and Tasks\n",
    "\n",
    "- Operators ⟶ Tasks ⟶ Task instances\n",
    "- Operators are Task \"factories\"\n",
    "- When a Taks is executed a Task instance is produced"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "```python\n",
    "from airflow.operators import BashOperator, MySqlOperator, PythonOperator\n",
    "\n",
    "bash_task = BashOperator(task_id = 'bash_task',\n",
    "                         bash_command = 'echo \"Hello PyCon\"',\n",
    "                         dag = dag)\n",
    "\n",
    "mysql_task = MySqlOperator(task_id = 'mysql_task',\n",
    "                           mysql_conn_id = 'mysql_db_conn',\n",
    "                           sql = 'query.sql',\n",
    "                           dag = dag)\n",
    "                           \n",
    "py_task = PythonOperator(task_id = 'py_task',\n",
    "                         python_callable = py_function,\n",
    "                         op_kwargs = {'arg' : 'value'},\n",
    "                         dag = dag)\n",
    "                         \n",
    "mysql_task.set_upstream(bash_task)\n",
    "\n",
    "py_task.set_upstream(mysql_task)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Airflow - API and Concepts\n",
    "\n",
    "### Workflow Building Blocks - Operators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Local:\n",
    "    - BashOperator\n",
    "    - PythonOperator\n",
    "    - DockerOperator\n",
    "    - S3FileTransformOperator\n",
    "\n",
    "- Remote:\n",
    "    - SimpleHttpOperator\n",
    "    - [Hive|Pig|BigQuery]Operator\n",
    "    - [MySql|Postgres|Sqlite|Jdbc|MsSql|Oracle]Operator\n",
    "    - [PrestoCheck|PrestoValueCheck|PrestoIntervalCheck]Operator\n",
    "\n",
    "- Messaging:\n",
    "    - EmailOperator\n",
    "    - [SlackAPI|SlackAPIPost]Operator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Airflow - API and Concepts\n",
    "\n",
    "### Workflow Building Blocks - Operators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Transfer:\n",
    "    - GenericTransfer\n",
    "    - [MySqlToHive|S3ToHive|HiveToMySql]Transfer\n",
    "    - [PrestoToMySql|HiveToDruid]Transfer\n",
    "\n",
    "- Flow:\n",
    "    - [BranchPython|ShortCircuit]Operator\n",
    "    - [TriggerDagRun|SubDag]Operator\n",
    "    - DummyOperator\n",
    "\n",
    "- Sensors:\n",
    "    - [ExternalTask|Hdfs|HivePartition|Http|MetastorePartition]Sensor\n",
    "    - [S3Key|S3Prefix|Sql|TimeDelta|Time|WebHdfs]Sensor\n",
    "\n",
    "- Other (contributed):\n",
    "    - Ssh, GCS, Spark SQL, Sqoop, Vertica, AWS EMR, Hipchat\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Airflow - API and Concepts\n",
    "\n",
    "### A real-life DAG\n",
    "\n",
    "![](img/dag-example.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Airflow - API and Concepts\n",
    "\n",
    "### Key Elements\n",
    "\n",
    "- Hooks: the building blocks of operators\n",
    "\n",
    "   ```python\n",
    "   from airflow.hooks import MySqlHook\n",
    "   \n",
    "   mysql_db = MySqlHook(mysql_conn_id = \"mysql_dwh\")\n",
    "   result = mysql_db.get_first(sql = \"SELECT 'Airflow is cool' AS txt;\")\n",
    "   ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Airflow - API and Concepts\n",
    "\n",
    "### Key Elements\n",
    "\n",
    "- Connections\n",
    "\n",
    "![connections-ui](img/connection.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Airflow - API and Concepts\n",
    "\n",
    "### Further Elements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Variables and XComs ⟶ Share \"state\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Templates (Jinja) and Macros ⟶ Patterns and/or Parametrization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Pools and queues ⟶ Resources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- SubDAGs, Branches and trigger rules ⟶ Flow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- SLAs and policies ⟶ Quality and accountability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Documentation and notes ⟶ Collaboration and maintainability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Airflow - Scheduler\n",
    "\n",
    "\n",
    "<img src=\"https://www.tangentehr.com/final/wp-content/uploads/2015/03/Enterprise-Schedular-2-512x512.png\" alt=\"scheduler\" style=\"width: 100px;\"/>\n",
    "\n",
    "        airflow scheduler -n $NUM\n",
    "        \n",
    "- Monitors and triggers the DAGs creating `DAG Runs` and starting the executor\n",
    "\n",
    "- First `DAG Run` from DAG's `start_date`\n",
    "\n",
    "- Subsequent runs based on `schedule_interval` (cron expression or `datetime.timedelta`)     \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Airflow - Web UI\n",
    "\n",
    "![](http://airflow.incubator.apache.org/_images/airflow.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Airflow - CLI\n",
    "\n",
    "<img src=\"http://cdn.osxdaily.com/wp-content/uploads/2014/07/iterm2-icon.jpg\" alt=\"cli\" style=\"width: 80px;\"/>\n",
    "\n",
    "Rich set of commands for dev-ops: `airflow [-h] <command>`\n",
    "\n",
    "**Core services**\n",
    "        \n",
    "        webserver -p 80\n",
    "        scheduler -n $NUM\n",
    "**Meta-DB operations**\n",
    "       \n",
    "       initdb resetdb upgradedb\n",
    "**Operate on DAGs**\n",
    "       \n",
    "       pause unpause run trigger_dag backfill dag_state task_state clear\n",
    "\n",
    "**Development and test**\n",
    "\n",
    "       list_dags list_tasks variables render test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Airflow - Deployment\n",
    "\n",
    "### Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Setup a meta-DB (SQLALchemy powered) for the backend (executor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Setup the env var for Airflow and the config file:\n",
    "    - `$AIRFLOW_HOME`\n",
    "    - `$AIRFLOW_HOME/airflow.cfg`\n",
    "\n",
    " Key vars: `airflow_home`, `dags_folder`, `executor`, `sql_alchemy_conn`, `parallelism`, `dag_concurrency`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Initialiaze the DB (once)\n",
    "\n",
    "        airflow initdb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Airflow - Deployment\n",
    "\n",
    "### Initialize\n",
    "\n",
    "        airflow webserver -p 80\n",
    "        airflow scheduler -n $NUM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Run as a service\n",
    "\n",
    "- Setup Airflow (Web UI and Scheduler) as services with systemd or upstart (launchd in OSX):\n",
    "\n",
    "   - [`scripts/systemd`](https://github.com/apache/incubator-airflow/tree/master/scripts/systemd)\n",
    "   - [`scripts/upstart`](https://github.com/apache/incubator-airflow/tree/master/scripts/upstart)    \n",
    "\n",
    "            initctl start airflow-webserver\n",
    "            initctl start airflow-scheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Resources and References\n",
    "\n",
    "- GitHub: https://github.com/apache/incubator-airflow\n",
    "\n",
    "- Docs: http://airflow.incubator.apache.org/\n",
    "\n",
    "- Wiki: https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Home\n",
    "    - Further links: https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Links\n",
    "    - Common pitfalls: https://cwiki.apache.org/confluence/display/AIRFLOW/Common+Pitfalls\n",
    "\n",
    "- [Maxime Beauchemin's original presentation](http://www.slideshare.net/Hadoop_Summit/airflow-an-open-source-platform-to-author-and-monitor-data-pipelines)\n",
    "\n",
    "- ETL With Airflow (deep example) https://github.com/gtoonstra/etl-with-airflow\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Colophon\n",
    "\n",
    "#### [**demorenoc.github.io/slides/pycon-co-2017/airflow**](https://demorenoc.github.io/slides/pycon-co-2017/airflow)\n",
    "\n",
    "This presentation was written in a [Jupyter Notebook](https://jupyter.org) (available [here](https://github.com/demorenoc/slides/blob/gh-pages/pycon-co-2017/airflow/moving-tranforming-data-airflow.ipynb)) and compiled into a [reveal.js](http://lab.hakim.se/reveal-js) presentation by [`nbconvert`](https://nbconvert.readthedocs.io/en/latest/) in the default slides template and powered by [CDNJS](https://cdnjs.com/). Published online in [GitHub](https://github.com/demorenoc/slides) thanks to [GitHub Pages](https://pages.github.com/).\n",
    "\n",
    "This presentation was prepared by [Daniel Moreno](https://github.com/demorenoc) for a talk given in [PyCon.co](http://www.pycon.co/) and it's original content (not much really) is under the [CC-BY 4.0](http://creativecommons.org/licenses/by/4.0/) license.\n",
    "\n",
    "[![CC BY](http://i.creativecommons.org/l/by/4.0/88x31.png)](http://creativecommons.org/licenses/by/4.0/ \"WEB\")"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
