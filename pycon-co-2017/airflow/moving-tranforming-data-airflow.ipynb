{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Moving and Transforming Data with\n",
    "\n",
    "# Airflow\n",
    "\n",
    "<br/>\n",
    "\n",
    "![Airflow](https://raw.githubusercontent.com/apache/incubator-airflow/master/airflow/www/static/pin_100.png)\n",
    "\n",
    "<br/>\n",
    "\n",
    "*[Daniel Moreno](https://github.com/demorenoc)*\n",
    "\n",
    "*Data Science & Analytics - [Mercadoni](https://www.mercadoni.com.co)*\n",
    "\n",
    "*PyCon Colombia (2017-02-10 - 2017-02-11)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Hi\n",
    "<br/>\n",
    "I am Daniel.\n",
    "\n",
    "I am a statistician.\n",
    "\n",
    "\n",
    "<i class=\"fa fa-github\" aria-hidden=\"true\"></i> [@demorenoc](htpps://github.com/demorenoc)\n",
    "<br/>\n",
    "<i class=\"fa fa-linkedin\" aria-hidden=\"true\"></i> [in/demorenoc](https://www.linkedin.com/in/demorenoc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Currently:\n",
    "<img src=\"https://s29.postimg.org/pm48ubxfr/mercadonilogobig_3x.png\" alt=\"Mercadoni\" style=\"width: 300px;\"/>\n",
    "\n",
    "### Previously:\n",
    "<img src=\"https://tappsi.co/wp-content/press-kit/logo/logo-principal-02.png\" alt=\"Tappsi\" style=\"width: 300px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Motivation\n",
    "\n",
    "- Complex and diverse processes\n",
    "\n",
    "![](http://www.intorobotics.com/wp-content/uploads/2014/10/HRInternetofThingsStandardsiStockphoto27050372-1393867723706.jpg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Motivation\n",
    "\n",
    "- *Continously available* and *usable* data is key for modern companies success\n",
    "![](http://databasesquad.net/wp-content/uploads/2014/08/data-warehouse-services.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Motivation\n",
    "\n",
    "- **Moving and transforming data** can get costly\n",
    "\n",
    "![](http://vignette3.wikia.nocookie.net/lego/images/6/6c/Janitor.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Desideratum\n",
    "\n",
    "![](https://decisions.com/wp-content/uploads/2015/11/99-c.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Desideratum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Compact, homogeneous **code**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Simplicity (defining workflows and **colaborating**)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Flexibility (modularity + extensibility)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Traceability/accountability and ownership"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Operational metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Scaleability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Automation (**programmatic**/dynamic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Useful UI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Flat learning curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Airflow\n",
    "\n",
    "<br/>\n",
    "\n",
    "![Airflow](https://raw.githubusercontent.com/apache/incubator-airflow/master/airflow/www/static/pin_100.png)\n",
    "\n",
    "![Incubator](http://incubator.apache.org/images/egg-logo2.png)\n",
    "\n",
    "Originally by [Maxime Beauchemin @mistercrunch](https://github.com/mistercrunch) from Airbnb.\n",
    "<br/>\n",
    "\n",
    "https://github.com/apache/incubator-airflow\n",
    "\n",
    "https://airflow.incubator.apache.org/\n",
    "\n",
    "<br/>\n",
    "\n",
    "```sh\n",
    "pip install airflow\n",
    "pip install \"airflow[mysql]\"\n",
    "pip install \"airflow[postgres]\"\n",
    "pip install \"airflow[crypto, password]\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Alternatives\n",
    "\n",
    "- Luigi by Spotify <img src=\"https://raw.githubusercontent.com/spotify/luigi/master/doc/luigi.png\" alt=\"Luigi\" style=\"width: 150px;\"/>\n",
    "\n",
    "- Pinball by Pinterest\n",
    "\n",
    "- See a some comparisons:\n",
    "     - [Luigi vs Airflow vs Pinball](http://bytepawn.com/luigi-airflow-pinball.html#luigi-airflow-pinball)\n",
    "     - [Apache Airflow - Presentation by Sumit Maheshwari (Quoble)](http://www.slideshare.net/sumitmaheshwari007/apache-airflow)\n",
    "\n",
    "## For Hadoop\n",
    "\n",
    "- Azkaban by LinkedIn\n",
    "\n",
    "- Apache Oozie (originally by Yahoo!) ![](http://oozie.apache.org/images/oozie_200x.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Airflow - Main Components\n",
    "\n",
    "- API (http://airflow.incubator.apache.org/code.html#api-reference)\n",
    "```python\n",
    "from airflow import DAG\n",
    "from airflow.operators import SimpleHttpOperator, MySqlOperator\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Scheduler\n",
    "        airflow scheduler -n 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Web UI\n",
    "        airflow webserver -p 80"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- CLI\n",
    "        airflow --help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Executor (\"backend\" system)\n",
    "    - Sequential\n",
    "    - Local\n",
    "    - Celery (and Mesos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Airflow - Architecture\n",
    "\n",
    "![Airflow-Architecture](https://image.slidesharecdn.com/june101115amairbnbbeaucheminv2-150701231554-lva1-app6892/95/airflow-an-open-source-platform-to-author-and-monitor-data-pipelines-23-638.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Concepts and API\n",
    "\n",
    "![](img/dag-example.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Workflow Building Blocks - DAG\n",
    "\n",
    "- DAG: Directed Acyclic Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "```python\n",
    "from airflow import DAG\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "default_args = {'owner': 'daniel', 'email': ['daniel.moreno@mercadoni.com'],\n",
    "                'start_date': datetime(2017, 2, 10), 'depends_on_past': False,\n",
    "                'retries': 1, 'retry_delay': timedelta(seconds = 30),\n",
    "                # 'pool' : 'main',\n",
    "                # 'sla' : timedelta(minutes = 30),\n",
    "                # 'execution_timeout' : timedelta(minutes = 5),\n",
    "                # 'on_failure_callback' : failure_function,\n",
    "                # 'on_success_callback': success_function,\n",
    "                # 'on_retry_callback': retry_function,\n",
    "                # 'trigger_rule': 'all_success'\n",
    "               }\n",
    "\n",
    "dag = DAG(dag_id            = 'model',\n",
    "          schedule_interval = timedelta(minutes = 10), # '0/10 * * * *'\n",
    "          default_args      = default_args,\n",
    "          dagrun_timeout    = timedelta(minutes = 3)\n",
    "          # template_searchpath = ['path/to/queries'],\n",
    "          # concurrency = 4,\n",
    "          # max_active_runs = 1,\n",
    "          # sla_miss_callback = sla_alert_function\n",
    "          )\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Workflow Building Blocks - Operators and Tasks\n",
    "\n",
    "- Operators ⟶ Tasks ⟶ Task instances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "```python\n",
    "from airflow.operators import BashOperator, MySqlOperator, PythonOperator\n",
    "\n",
    "bash_task = BashOperator(task_id = 'bash_task',\n",
    "                         bash_command = 'echo \"Hello PyCon\"',\n",
    "                         dag = dag)\n",
    "\n",
    "mysql_task = MySqlOperator(task_id = 'mysql_task',\n",
    "                           mysql_conn_id = 'mysql_db_conn',\n",
    "                           sql = 'query.sql',\n",
    "                           dag = dag)\n",
    "                           \n",
    "py_task = PythonOperator(task_id = 'py_task',\n",
    "                         python_callable = py_function,\n",
    "                         dag = dag,\n",
    "                         op_kwargs = {'arg' : 'value'}, \n",
    "                         # ... other ways to pass arguments\n",
    "                         )\n",
    "                         \n",
    "mysql_task.set_upstream(bash_task)\n",
    "\n",
    "py_task.set_upstream(mysql_task)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Workflow Building Blocks\n",
    "\n",
    "![](img/dag-example-0.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Workflow Building Blocks - Operators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Local:\n",
    "    - BashOperator\n",
    "    - PythonOperator\n",
    "    - DockerOperator\n",
    "    - S3FileTransformOperator\n",
    "\n",
    "- Remote:\n",
    "    - SimpleHttpOperator\n",
    "    - [Hive|Pig|BigQuery]Operator\n",
    "    - [MySql|Postgres|Sqlite|Jdbc|MsSql|Oracle]Operator\n",
    "    - [PrestoCheck|PrestoValueCheck|PrestoIntervalCheck]Operator\n",
    "\n",
    "- Messaging:\n",
    "    - EmailOperator\n",
    "    - [SlackAPI|SlackAPIPost]Operator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Workflow Building Blocks - Operators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Transfer:\n",
    "    - GenericTransfer\n",
    "    - [MySqlToHive|S3ToHive|HiveToMySql]Transfer\n",
    "    - [PrestoToMySql|HiveToDruid]Transfer\n",
    "\n",
    "- Flow:\n",
    "    - [BranchPython|ShortCircuit]Operator\n",
    "    - [TriggerDagRun|SubDag]Operator\n",
    "    - DummyOperator\n",
    "\n",
    "- Sensors:\n",
    "    - [ExternalTask|Hdfs|HivePartition|Http|MetastorePartition]Sensor\n",
    "    - [S3Key|S3Prefix|Sql|TimeDelta|Time|WebHdfs]Sensor\n",
    "\n",
    "- Other (contributed):\n",
    "    - Ssh, GoogleCloudStorage, Spark SQL, Sqoop, Vertica, AWS EMR, Hipchat\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Key Elements\n",
    "\n",
    "- Hooks: the building blocks of operators\n",
    "\n",
    "   ```python\n",
    "   from airflow.hooks import MySqlHook\n",
    "   \n",
    "   mysql_db = MySqlHook(mysql_conn_id = \"mysql_dwh\")\n",
    "   result = mysql_db.get_first(sql = \"SELECT 'Airflow is cool' AS txt;\")\n",
    "   ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Key Elements\n",
    "\n",
    "- Connections\n",
    "\n",
    "![connections-ui](img/connection.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Further Elements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Variables and XComs ⟶ Share \"state\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Templates (Jinja) ⟶ Patterns and/or Parametrization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Pools and queues ⟶ Resources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- SubDAGs, Branches and trigger rules ⟶ Flow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- SLAs and policies ⟶ Quality and accountability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Documentation and notes ⟶ Collaboration and maintainability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Web UI\n",
    "\n",
    "![](http://airflow.incubator.apache.org/_images/airflow.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# CLI and Deployment\n",
    "\n",
    "- Setup a DB (SQLALchemy) for the backend (executor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Setup the env var for Airflow and the config file:\n",
    "    - `$AIRFLOW_HOME`\n",
    "    - `$AIRFLOW_HOME/airflow.cfg`\n",
    "\n",
    " Key vars: `airflow_home`, `dags_folder`, `executor`, `sql_alchemy_conn`, `parallelism`, `dag_concurrency`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Initialiaze the DB\n",
    "\n",
    "        airflow initdb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Ready to initialize the services:\n",
    "\n",
    "        airflow webserver -p 80\n",
    "        airflow scheduler -n $NUM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Run as a service\n",
    "\n",
    "- Setup Airflow (Web UI and Scheduler) as services with systemd or upstart (launchd in OSX):\n",
    "\n",
    "   - [`scripts/systemd`](https://github.com/apache/incubator-airflow/tree/master/scripts/systemd)\n",
    "   - [`scripts/upstart`](https://github.com/apache/incubator-airflow/tree/master/scripts/upstart)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "            initctl start airflow-webserver\n",
    "            initctl start airflow-scheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Resources and References\n",
    "\n",
    "- GitHub: https://github.com/apache/incubator-airflow\n",
    "\n",
    "- Docs: http://airflow.incubator.apache.org/\n",
    "\n",
    "- Wiki: https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Home\n",
    "    - Further links: https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Links\n",
    "    - Common pitfalls: https://cwiki.apache.org/confluence/display/AIRFLOW/Common+Pitfalls\n",
    "\n",
    "- [Maxime Beauchemin's original presentation](http://www.slideshare.net/Hadoop_Summit/airflow-an-open-source-platform-to-author-and-monitor-data-pipelines?next_slideshow=5)\n",
    "\n",
    "- ETL With Airflow (deep example) https://github.com/gtoonstra/etl-with-airflow\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Colophon\n",
    "\n",
    "#### [**demorenoc.github.io/slides/pycon-co-2017/airflow**](https://demorenoc.github.io/slides/pycon-co-2017/airflow)\n",
    "\n",
    "This presentation was written in a [Jupyter Notebook](https://jupyter.org) and compiled into a [reveal.js](http://lab.hakim.se/reveal-js) presentation by [`nbconvert`](https://nbconvert.readthedocs.io/en/latest/) in the default slides template and powered by [CDNJS](https://cdnjs.com/). Published online in [GitHub](https://github.com/demorenoc/slides) thanks to [GitHub Pages](https://pages.github.com/).\n",
    "\n",
    "This presentation was prepared by [Daniel Moreno](https://github.com/demorenoc) for a talk given in [PyCon.co](http://www.pycon.co/) and it's original content (not much really) is under the [CC-BY 4.0](http://creativecommons.org/licenses/by/4.0/) license.\n",
    "\n",
    "[![CC BY](http://i.creativecommons.org/l/by/4.0/88x31.png)](http://creativecommons.org/licenses/by/4.0/ \"WEB\")"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
